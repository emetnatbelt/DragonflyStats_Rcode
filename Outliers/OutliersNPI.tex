\documentclass[MdouleBmain.tex]{subfiles}

\begin{document}


\subsection{Logarithmic  Transformation}

If data deviate substantially from a Gaussian distribution, using a nonparametric test is not the only alternative. Consider transforming the data to create a Gaussian distribution. Transforming to reciprocals or logarithms are often helpful.
Data can fail a normality test because of the presence of an outlier. Removing that outlier can restore normality.
The decision of whether to use a parametric or nonparametric test is most important with small data sets (since the power of nonparametric tests is so low). But with small data sets, normality tests have little power to detect non-normal distributions, so an automatic approach would give you false confidence.

With large data sets, normality tests can be too sensitive. A low p-value from a normality test tells you that there is strong evidence that the data are not sampled from an ideal normal distribution. But you already know that, as almost no scientifically relevant variables form an ideal normal distribution. What you want to know is whether the distribution deviates enough from the normal ideal to invalidate conventional statistical tests (that assume a Gaussian distribution). A normality test does not answer this question. With large data sets, trivial deviations from the idea can lead to a small p-value.

\subsection{Outlier Detection}
One of the first steps towards obtaining a coherent analysis is the detection of outlaying observations. Although outliers are often considered as an error or noise, they may carry important information (see Mandelbrot/Taleb).

Detected outliers are candidates for aberrant data that may otherwise adversely lead to model misspecification, biased parameter estimation and incorrect results. It is therefore
important to identify them prior to modelling and analysis.

Outlier detection methods have been suggested for numerous applications, such as credit card fraud detection, clinical trials, voting irregularity analysis, data cleansing, network intrusion, severe weather prediction, geographic information systems and athlete performance analysis.

%----------------------------------------------------------------------------------------------------%
\section{Outliers}
If the outlier test identifies one or more values as being an outlier, we must consider the following

1.	Was the outlier value entered into the computer incorrectly?
If the "outlier" is in fact a typo, fix it. It is always worth going back to the original data source, and checking that outlier value entered into Prism is actually the value you obtained from the experiment. If the value was the result of calculations, check for math errors.

2.	Is the outlier value scientifically impossible?
Of course you should remove outliers from your data when the value is completely impossible. Examples include a negative weight, or an age (of a person) that exceed 150 years. Those are clearly errors, and leaving erroneous values in the analysis would lead to nonsense results.

3.	Is the assumption of a Normal distribution dubious?
The Grubbs' tests assume that all the values are sampled from a Gaussian distribution, with the possible exception of one (or a few) outliers from a different distribution. If the underlying distribution is not Gaussian, then the results of the outlier test is unreliable. It is especially important to beware of lognormal distributions. If the data are sampled from a lognormal distribution, you expect to find some very high values which can easily be mistaken for outliers. Removing these values would be a mistake.

4.	Is the outlier value potentially scientifically interesting?
If each value is from a different animal or person, identifying an outlier might be important. Just because a value is not from the same normal distribution as the rest doesn't mean it should be ignored. An interesting phenomenon may have been discovered. Don't discard  the data as an outlier without considering if the observation is potentially scientifically interesting. 

5.	 Do the data records indicate any sort of experimental problem with that value
It is easier to justify removing a value from the data set when it is not only tagged as an "outlier" by an outlier test, but you also recorded problems with that value when the experiment was performed.
6.	 Do you have a policy on when to remove outliers?
Ideally, removing an outlier should not be an ad hoc decision. In general , you should follow a policy, and apply that policy consistently.

7.	 If you are looking for two or more outliers, could masking be a problem?
\textbf{\texttt{Masking}} is the name given to the problem where the presence of two (or more) outliers, can make it harder to find even a single outlier.

If you answered no to all those questions.
If you've answered no to all the questions above, there are two possibilities:
The suspect value came from the same normal population as the other values. You just happened to collect a value from one of the tails of that distribution.
	
The suspect value came from a different distribution than the rest. Perhaps it was due to a mistake, such as bad pipetting, voltage spike, holes in filters, etc. 

If you knew the first possibility was the case, you would keep the value in your analyses. Removing it would be a mistake.
If you knew the second possibility was the case, you would remove it, since including an erroneous value in your analyses will give invalid results. 

The problem, of course, is that you can never know for sure which of these possibilities is correct. An outlier test cannot answer that question for sure. Ideally, you should create a lab policy for how to deal with such data, and follow it consistently.
If you don't have a lab policy on removing outliers, here is suggestion: Analyze your data both with and without the suspected outlier. If the results are similar either way, you've got a clear conclusion. If the results are very different, then you are stuck. Without a consistent policy on when you remove outliers, you are likely to only remove them when it helps push the data towards the results you want.


\subsection{Grubbsâ€™ Test}
Grubbs' test is a formal hypothesis test for assessing whether or not a  data set contains an outlier.
This data set is univariate and approximately normal distributed. This test is designed for assessing one outlier only.  If more outliers are suspected, alternative tests, such as the Tietjen-Moore test, are recommended.
Hypotheses: Grubbs' test is defined for the hypothesis: 
\begin{description}
\item[Ho] :  There are no outliers in the data set  
\item[Ha] :  There is exactly one outlier in the data set  
\end{description}

\begin{framed}
\begin{verbatim}
install.packages("outliers")
library(outliers)
#Package Author : Lukasz Komsta (UMLUB, Poland)

grubbs.test(DAT002)
\end{verbatim}
\end{framed}



\section{Non-Parametric Tests}
Many statistical tests assume that you have sampled data from populations that follow a Normal distribution. 
Biological data never follow a Gaussian distribution precisely, because a Gaussian distribution extends infinitely in both directions, and so it includes both infinitely low negative numbers and infinitely high positive numbers. But many kinds of biological data follow a bell-shaped distribution that is approximately Gaussian. 

Because statistical tests work well even if the distribution is only approximately Gaussian (especially with large samples), these tests are used routinely in many fields of science.

An alternative approach does not assume that data follow a Gaussian distribution. These tests, called nonparametric tests, are appealing because they require fewer assumptions about the distribution of the data. In this approach, values are ranked from low to high, and the analyses are based on the distribution of ranks.
Often, the analysis will be one of a series of experiments. Since you want to analyze all the experiments the same way, you cannot rely on the results from a single normality test.


\end{document}
